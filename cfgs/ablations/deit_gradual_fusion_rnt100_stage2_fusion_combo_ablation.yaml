# General parameters
use_optuna: True
train_stage: 2  
output_dir: '/data/datasets/research-datasets/output_dir'
seed: 508926194
phase: 'train'

# Dataset parameters
dataroot: '/data/datasets/research-datasets'
dataset: 'reid_mm/RGBNT100'
dataset_name: 'RGBNT100'

input_size: [224, 224] # 224 normally, 384 for larger deit

data_augmentation: True
hflip: 0.5 # threshold for random horizontal flip
resize_min: 0.8 # only if data_augmentation is True
resize_max: 1.0 # only if data_augmentation is True

augment_type: 'random_erasure' # Optional: "random_erasure"
train_ratio: 0.8 # use 80% of the data for training and 20% for validation
image_num_for_reid_validate: 25 # Default 25
num_triplet_samples: 8 # Default 1

# Model parameters 
model_modalities: ['R', 'N', 'T']
model_num_cls_tokens: 0
model_num_fusion_tokens: 1
model_num_heads: 8
vit_embed_dim: 768 # 384 for dino, 768 normally
model_decoder_output_class_num: 50 # change this when changing datasets
model_fusion_combos: 'fdf'
model_lrnable_fusion_avg: False
data_token_step: 0
pretrained_model: "distilled-224"
unfreeze_transformer_backbone: True
lagging_modality_token: True
one_hot: True

# Loss parameters
loss_fn: "center+ce+triplet_euclidean_soft_margin" 
triplet_loss_weighting: 0.5 
ce_loss_weighting: 0.5 
center_loss_weighting: 0.0005
label_smoothing: 0.1

# Optimizer parameters
optimizer: 'adamw'
lr: 0.0000057433
weight_decay: 0.001303446
beta1: 0.8363999
beta2: 0.978528
lr_scheduler_name: '' # Different from stage 1
warmup_steps: 500
max_lr: 0.01
reset_scheduler: False

# Training parameters
gpus: [0, 1, 2, 3, 4, 5, 6, 7]

ckpt_dir: '/data/datasets/research-datasets/ckpt_dir'
ckpt_full_path: '/data/datasets/research-datasets/ckpt_dir/20230829-112804-deit-rnt100-augmented-triplet/best.pth'

# dff: /data/datasets/research-datasets/ckpt_dir/20230829-115305-deit-rnt100-augmented-triplet/best.pth
# ddf: /data/datasets/research-datasets/ckpt_dir/20230829-114354-deit-rnt100-augmented-triplet/best.pth
# dfd: /data/datasets/research-datasets/ckpt_dir/20230829-113503-deit-rnt100-augmented-triplet/best.pth
# fdf: /data/datasets/research-datasets/ckpt_dir/20230829-112804-deit-rnt100-augmented-triplet/best.pth
# ddd: /data/datasets/research-datasets/ckpt_dir/20230829-111752-deit-rnt100-augmented-triplet/best.pth
# fdd: /data/datasets/research-datasets/ckpt_dir/20230829-111638-deit-rnt100-augmented-triplet/best.pth
# fff: /data/datasets/research-datasets/ckpt_dir/20230829-105537-deit-rnt100-augmented-triplet/best.pth

batch_size: 26
num_epochs: 50
print_freq: 50
model_name: "deit_gradual_fusion"
trainer_name: "trainer_rgbn_triplet"
verbose: True # Setting for printing more information
max_rank: 50 # Max number of ranks to calculate cmc and mAP
n_trials: 1 # Number of trials for optuna

# Weights and Biases Logging
use_wandb: True
wandb_project: 'mm-mafia-reid-new-mAP'
study_name: 'rnt100-fusion_combo-ablation-stage2'
wandb_run_name: 'stage2-fdf' 
wandb_trial_name: 'stage2-fdf'


hyperparams:
  lr:
    min: 0.0000057433
    max: 00.0000057433
    type: loguniform
  weight_decay:
    min: 0.001303446
    max: 0.001303446
    type: loguniform
  beta1:
    min: 0.8363999
    max: 0.8363999
    type: float
  beta2:
    min: 0.978528
    max: 0.978528
    type: float
  model_num_cls_tokens: 
    min: 0
    max: 0
    type: int
  model_num_fusion_tokens: 
    min: 1
    max: 1
    type: int
